{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b488df-7345-441f-8e1f-1ba078013002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95b14491-e94a-4127-a9f7-34b9326ae73e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:977: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:964: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 09:00:19.006625: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2024-07-17 09:00:19.011416: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2394285000 Hz\n",
      "2024-07-17 09:00:19.012002: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563dc2cb9070 executing computations on platform Host. Devices:\n",
      "2024-07-17 09:00:19.012063: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2024-07-17 09:00:19.117249: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 475.5199922967593\n",
      "Standard deviation of MSE: 1053.2755765559464\n"
     ]
    }
   ],
   "source": [
    "#Part A\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "\n",
    "# Define predictors and target\n",
    "X = df.drop(columns=['Strength'])\n",
    "y = df['Strength']\n",
    "\n",
    "# Create a list of mean squared errors\n",
    "mse_list = []\n",
    "\n",
    "for _ in range(50):\n",
    "    # Split the data using train_test_split function\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=None)\n",
    "    \n",
    "    # Build the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list.append(mse)\n",
    "    \n",
    "    \n",
    "# Report mean and standard deviation\n",
    "\n",
    "mean_mse = np.mean(mse_list)\n",
    "std_mse = np.std(mse_list)\n",
    "\n",
    "print(f\"Mean MSE: {mean_mse}\")\n",
    "print(f\"Standard deviation of MSE: {std_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903046cf-861c-4210-8a54-e288adb4cc3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part B\n",
    "\n",
    "\n",
    "# Normalize the data by subtracting the mean and dividing by standard deviation\n",
    "\n",
    "X_normalized = (X - X.mean()) / X.std()\n",
    "\n",
    "# Create a list of mean squared errors\n",
    "mse_list_normalized = []\n",
    "\n",
    "for _ in range(50):\n",
    "    # Split the data using train_test_split function\n",
    "    X_tran, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=None)\n",
    "    \n",
    "    # Build the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    \n",
    "    #Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list_normalized.append(mse)\n",
    "    \n",
    "# Report mean and standard deviation\n",
    "\n",
    "mean_mse_normalized = np.mean(mse_list_normalized)\n",
    "std_mse_normalized = np.std(mse_list_normalized)\n",
    "\n",
    "print(f\"Mean MSE (Normalized): {mean_mse_normalized}\")\n",
    "print(f\"Standard Deviation of MSE (Normalized): {std_mse_normalized}\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Normalization in this case resulted in a higher mean MSE compared to the baseline. \n",
    "This suggests that the model did not benefit from normalization, which might be due to the nature of the data.\n",
    "The standard deviation of the MSE significantly decreased, indicating that normalization made\n",
    "the training process more stable and consistent across different runs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e36a6-1b29-4809-8a47-e2f3c919d7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part C\n",
    "\n",
    "# Create a list of mean squared errors\n",
    "mse_list_100_epochs = []\n",
    "\n",
    "for _ in range(50):\n",
    "    # Split the data using train_test_split function\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=None)\n",
    "    \n",
    "    # Build the model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model increasing epochs to 100\n",
    "    model.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list_100_epochs.append(mse)\n",
    "    \n",
    "# Report mean and standard deviation\n",
    "mean_mse_100_epochs = np.mean(mse_list_100_epochs)\n",
    "std_mse_100_epochs = np.std(mse_list_100_epochs)\n",
    "\n",
    "print(f\"Mean MSE (Normalized, 100 Epochs): {mean_mse_100_epochs}\")\n",
    "print(f\"Standard Deviation of MSE (Normalized, 100 Epochs): {std_mse_100_epochs}\")\n",
    "\n",
    "\"\"\"\n",
    "Training the model for 100 epochs led to a dramatic reduction in the mean MSE. \n",
    "The model was able to learn much better from the data given more epochs, which allowed for a more thorough training process.\n",
    "The standard deviation of the MSE further decreased, indicating very consistent performance across different runs. \n",
    "This demonstrates that with more epochs, the model converges better and produces more reliable results.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38a25183-421a-4814-9c15-c1b65273d58c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE (Normalized, 3 Hidden Layers): 125.77561950166174\n",
      "Standard Deviation of MSE (Normalized, 3 Hidden Layers): 20.09355128353075\n"
     ]
    }
   ],
   "source": [
    "# Part D\n",
    "\n",
    "# Create a list of mean squared errors\n",
    "mse_list_3_hidden_layers = []\n",
    "\n",
    "for _ in range(50):\n",
    "    # Split the data using train_test_split function\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=None)\n",
    "    \n",
    "    # Build the model increasing number of hidden layers to 3\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list_3_hidden_layers.append(mse)\n",
    "    \n",
    "# Report mean and standard deviation\n",
    "mean_mse_3_hidden_layers = np.mean(mse_list_3_hidden_layers)\n",
    "std_mse_3_hidden_layers = np.std(mse_list_3_hidden_layers)\n",
    "\n",
    "print(f\"Mean MSE (Normalized, 3 Hidden Layers): {mean_mse_3_hidden_layers}\")\n",
    "print(f\"Standard Deviation of MSE (Normalized, 3 Hidden Layers): {std_mse_3_hidden_layers}\")\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
